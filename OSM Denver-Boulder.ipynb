{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I downloaded the OSM data for the [Denver and Boulder, Colorado](https://mapzen.com/data/metro-extracts/metro/denver-boulder_colorado/) metro area. I had to download [7-Zip](http://www.7-zip.org/) to decompress the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample OSM area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code provided by Udacity\n",
    "OSM_FILE = \"denver-boulder_colorado.osm\"\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 15 # Parameter: take every k-th top level element; decrement to sample larger portions of data\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "            \n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auditing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Street types \n",
      "\n",
      "Colfax\n",
      "set(['East Colfax'])\n",
      "Bypass\n",
      "set(['Wadsworth Bypass'])\n",
      "Elm\n",
      "set(['East Elm'])\n",
      "Ln\n",
      "set(['Lee Ln'])\n",
      "West\n",
      "set(['Park Avenue West', 'South Carr Avenue West'])\n",
      "Main\n",
      "set(['Main'])\n",
      "314\n",
      "set(['County Road 314'])\n",
      "Rd\n",
      "set(['E Arapahoe Rd', 'Pine Valley Rd', 'S Parker Rd', 'S. Golden Rd'])\n",
      "Appia\n",
      "set(['Via Appia'])\n",
      "Way\n",
      "set(['Aberdeen Way',\n",
      "     'Airport Way',\n",
      "     'Castleton Way',\n",
      "     'Del Corso Way',\n",
      "     'Durham Way',\n",
      "     'East 60th Way',\n",
      "     'Golden Eagle Way',\n",
      "     'Iliad Way',\n",
      "     'Kincross Way',\n",
      "     'Landmark Way',\n",
      "     'Lioness Way',\n",
      "     'Mariposa Way',\n",
      "     'Meredith Way',\n",
      "     'Nyland Way',\n",
      "     'Pear Lake Way',\n",
      "     'Pine Bluffs Way',\n",
      "     'Pipit Lake Way',\n",
      "     'Progress Way',\n",
      "     'Rampart Way',\n",
      "     'Reed Way',\n",
      "     'S Cornerstar Way',\n",
      "     'S Ellipse Way',\n",
      "     'S Monaco Way',\n",
      "     'S Oneida Way',\n",
      "     'South Akron Way',\n",
      "     'South Alton Way',\n",
      "     'South Columbine Way',\n",
      "     'South Fultondale Way',\n",
      "     'South Gibraltar Way',\n",
      "     'South Grand Baker Way',\n",
      "     'South Monaco Way',\n",
      "     'South Pierce Way',\n",
      "     'South Trenton Way',\n",
      "     'South Xeric Way',\n",
      "     'South Yosemite Way',\n",
      "     'Spader Way',\n",
      "     'Summit Way',\n",
      "     'Ulster Way',\n",
      "     'West 68th Way',\n",
      "     'West 89th Way',\n",
      "     'Wisteria Way'])\n",
      "83\n",
      "set(['State Highway 83'])\n",
      "Ave.\n",
      "set(['E. College Ave.'])\n",
      "Circle\n",
      "set(['Adonia Circle',\n",
      "     'Argus Circle',\n",
      "     'Barberry Circle',\n",
      "     'Bedivere Circle',\n",
      "     'Camelot Circle',\n",
      "     'Coal Creek Circle',\n",
      "     'Corinth Circle',\n",
      "     'Cree Circle',\n",
      "     'Cypress Circle',\n",
      "     'Del Mar Circle',\n",
      "     'Dorchester Circle',\n",
      "     'Driftwood Circle',\n",
      "     'Durham Circle',\n",
      "     'Earle Circle',\n",
      "     'East Applewood Circle',\n",
      "     'East Carolina Circle',\n",
      "     'East Idaho Circle',\n",
      "     'East Lake Circle',\n",
      "     'East Sutton Circle',\n",
      "     'Essex Circle',\n",
      "     'Euclid Circle',\n",
      "     'Exempla Circle',\n",
      "     'Fairlawn Circle',\n",
      "     'Gateway Circle',\n",
      "     'Goss Circle',\n",
      "     'Greenbriar Circle',\n",
      "     'Gunbarrel Circle',\n",
      "     'Hermes Circle',\n",
      "     'Homer Circle',\n",
      "     'Ilium Circle',\n",
      "     'Julian Circle',\n",
      "     'Lambert Circle',\n",
      "     'Manorbrier Circle',\n",
      "     'Mesa Circle',\n",
      "     'Minotaur Circle',\n",
      "     'Pearl Circle',\n",
      "     'Polaris Circle',\n",
      "     'Rimrock Circle',\n",
      "     'Sagrimore Circle',\n",
      "     'Scorpios Circle',\n",
      "     'South Ivory Circle',\n",
      "     'South Maroon Circle',\n",
      "     'Squires Circle',\n",
      "     'St. Ida Circle',\n",
      "     'Starlight Circle',\n",
      "     'Sun Up Circle',\n",
      "     'Sunshine Circle',\n",
      "     'Sweetwater Circle',\n",
      "     'West Sutton Circle'])\n",
      "Rd.\n",
      "set(['E. Rim Rd.'])\n",
      "Pl\n",
      "set(['E Maplewood Pl', 'E Orchard Pl'])\n",
      "Baseline\n",
      "set(['Baseline'])\n",
      "200c\n",
      "set(['West 25th Avenue Suit 200c'])\n",
      "76\n",
      "set(['Frontage Road I -76'])\n",
      "East\n",
      "set(['Inverness Drive East', 'Sterling Circle East'])\n",
      "North\n",
      "set(['East Speer Boulevard North'])\n",
      "300\n",
      "set(['Commerce Center Cir #300'])\n",
      "2\n",
      "set(['Colorado SH 2', 'Colorado SR 2', 'Delaware St Unit 2'])\n",
      "Loop\n",
      "set(['Quay Loop'])\n",
      "Mall\n",
      "set(['Central Campus Mall', 'Pearl Street Mall'])\n",
      "8\n",
      "set(['49th St #8'])\n",
      "285\n",
      "set(['US Hwy 285'])\n",
      "287\n",
      "set(['US Highway 287'])\n",
      "Avenue)\n",
      "set(['East Bromley Lane (152nd Avenue)'])\n",
      "E\n",
      "set(['Arapahoe Rd E'])\n",
      "Center\n",
      "set(['Garden Center'])\n",
      "140\n",
      "set(['East Arapahoe Road, #140'])\n",
      "Mainstreet\n",
      "set(['East Mainstreet'])\n",
      "Plaza\n",
      "set(['Wewatta Plaza'])\n",
      "St\n",
      "set(['Dayton St',\n",
      "     'Jefferson St',\n",
      "     'S Clayton St',\n",
      "     'S Columbine St',\n",
      "     'S Elizabeth St',\n",
      "     'S Josephine St',\n",
      "     'S Newport St',\n",
      "     'S Pontiac St',\n",
      "     'S Quebec St',\n",
      "     'S Sherman St',\n",
      "     'South Grant St',\n",
      "     'W Mulberry St',\n",
      "     'Washington St',\n",
      "     'Wewatta St',\n",
      "     'Wright St'])\n",
      "120\n",
      "set(['West 120th Avenue, Ste 120'])\n",
      "Cir\n",
      "set(['Rock Creek Cir', 'S Lake Cir'])\n",
      "S\n",
      "set(['Oswego St S'])\n",
      "74\n",
      "set(['Highway 74'])\n",
      "73\n",
      "set(['County Road 73'])\n",
      "W\n",
      "set(['112th Ave W', '88th Ave W', 'Colfax Ave W'])\n",
      "Ave\n",
      "set(['Dawn Ave',\n",
      "     'E 6th Ave',\n",
      "     'E Fair Ave',\n",
      "     'E Maplewood Ave',\n",
      "     'Washington Ave'])\n",
      "220H\n",
      "set(['30th St #220H'])\n",
      "Campground\n",
      "set(['West Magnolia Campground'])\n",
      "Pkwy\n",
      "set(['Orchard Pkwy', 'S Monaco Pkwy'])\n",
      "South\n",
      "set(['Nautilus Court South'])\n",
      "Woodfern\n",
      "set(['Woodfern'])\n",
      "Point\n",
      "set(['Buchanan Point',\n",
      "     'Lodgewood Point',\n",
      "     'Red Feather Point',\n",
      "     'Sleeping Owl Point'])\n",
      "Dr\n",
      "set(['Community Circle Dr', 'Cowley Dr', 'Eisenhower Dr', 'Indian Peaks Dr'])\n",
      "Speer\n",
      "set(['Speer'])\n",
      "CO)\n",
      "set(['US 6 (CO)'])\n",
      "drive\n",
      "set(['City View drive'])\n",
      "Highway\n",
      "set(['South Valley Highway'])\n",
      "59\n",
      "set(['Weld County Road 59'])\n",
      "Av\n",
      "set(['W Belleview Av'])\n",
      "Blvd\n",
      "set(['Airport Blvd',\n",
      "     'Colorado Blvd',\n",
      "     'Green Valley Ranch Blvd',\n",
      "     'Sheridan Blvd',\n",
      "     'Wadsworth Blvd'])\n",
      "Broadway\n",
      "set(['Broadway', 'S Broadway', 'South Broadway'])\n",
      "Ct\n",
      "set(['S Niagra Ct'])\n",
      "\n",
      "\n",
      " Postcodes \n",
      "\n",
      "80514-8502\n",
      "set(['80514-8502'])\n",
      "CO\n",
      "set(['CO'])\n",
      "80214-1838\n",
      "set(['80214-1838'])\n",
      "80011-3316\n",
      "set(['80011-3316'])\n",
      "80504-7613\n",
      "set(['80504-7613'])\n",
      "80247-2121\n",
      "set(['80247-2121'])\n",
      "80012-4014\n",
      "set(['80012-4014'])\n",
      "80214-1801\n",
      "set(['80214-1801'])\n"
     ]
    }
   ],
   "source": [
    "expected_streets = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    \"\"\" set, str -> set\n",
    "    Given a set list of street types and v tag attribute for addr:street element,\n",
    "    add the attribute to the set and print if it's not in the list of expected\n",
    "    street types expected_streets.\n",
    "    \n",
    "    expected_streets = [\"Street\"]\n",
    "    audit_street_type(defaultdict(set), \"Parkway\")\n",
    "    \n",
    "    Parkway\n",
    "    ([\"Parkway\"])\n",
    "    \"\"\"\n",
    "    street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected_streets:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def audit_postcode(postcodes, postcode):\n",
    "    \"\"\" dict, str -> dict\n",
    "    Return dictionary of postcodes.\n",
    "    \"\"\"\n",
    "    p = re.match(r'^\\d{5}$', postcode)\n",
    "    if p:\n",
    "        return postcode\n",
    "    else:\n",
    "        postcodes[postcode].add(postcode)\n",
    "            \n",
    "def is_street_name(elem):\n",
    "    \"Return whether the element attribute is a street attribute.\"\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def is_postcode(elem):\n",
    "    \"Return whether the element attribute is a postcode attribute.\"\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "        \n",
    "def audit(osmfile):\n",
    "        osm_file = open(osmfile, \"r\")\n",
    "        street_types = defaultdict(set)\n",
    "        postcodes = defaultdict(set)\n",
    "        for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "            if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "                for tag in elem.iter(\"tag\"):\n",
    "                    if is_street_name(tag):\n",
    "                        audit_street_type(street_types, tag.attrib['v'])\n",
    "                    elif is_postcode(tag):\n",
    "                        audit_postcode(postcodes, tag.attrib['v'])\n",
    "        osm_file.close()\n",
    "        return street_types, postcodes\n",
    "    \n",
    "street_type_dict, postcode_dict = audit(SAMPLE_FILE)\n",
    "\n",
    "print \"\\n\\n Street types \\n\"\n",
    "for k, v in street_type_dict.items():\n",
    "    print k\n",
    "    pprint(v)\n",
    "    \n",
    "print \"\\n\\n Postcodes \\n\"\n",
    "for k, v in postcode_dict.items():\n",
    "    print k\n",
    "    pprint(v)\n",
    "    \n",
    "## Cleaning functions\n",
    "street_mapping = {\n",
    "    'Rd': 'Road',\n",
    "    'Rd.': 'Road',\n",
    "    'Ave.': 'Avenue',\n",
    "    'Ave': 'Avenue',\n",
    "    'Pl': 'Place',\n",
    "    'Dr': 'Drive',\n",
    "    'Cir': 'Circle',\n",
    "    'Blvd': 'Boulevard',\n",
    "    'St': 'Street',\n",
    "    'Ct': 'Court'\n",
    "    }\n",
    "\n",
    "def update_street_name(name, mapping): # from case study\n",
    "    ''' str, dict -> str\n",
    "    \n",
    "    print update_street_name('West 4th St.', {'St.':'Street'})\n",
    "    West 4th Street\n",
    "    \n",
    "    print update_street_name('North 57th Ct', street_mapping)\n",
    "    North 57th Court\n",
    "    '''\n",
    "    name = name.strip().split()\n",
    "    if name == []:\n",
    "        return \"\"\n",
    "    if name[-1] in mapping:\n",
    "        name[-1] = mapping[name[-1]]\n",
    "    output = \" \".join(name)\n",
    "    return output\n",
    "\n",
    "def update_postcode(postcode):\n",
    "    \"\"\" str -> str\n",
    "    Search for a full postcode in a string and return the first 5 digits.\n",
    "    \n",
    "    Adapted from: https://stackoverflow.com/questions/7425860/regular-expression-get-us-zip-code\n",
    "    \n",
    "    print update_postcode('80113-1525')\n",
    "    80113\n",
    "    \n",
    "    print update_postcode('Golden, CO 80401')\n",
    "    80401\n",
    "    \n",
    "    print update_postcode('CO 80223')\n",
    "    80223\n",
    "    \"\"\"\n",
    "    match = re.search('(\\d{5})([- ])?(\\d{4})?', postcode)\n",
    "    if match: \n",
    "        return match.groups()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a future pass, I'd like to standardize names like \"S Monaco Way\" or \"S. Monaco Way\" to \"South Monaco Way\". Similarly, some streets have the direction on the end like \"Arapahoe Road E\" that should read \"Arapahoe Road East\". I didn't do that here because of alphabetical streets like \"A Street\" or \"E Streets\" that might be incorrectly changed to \"East Street\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load schema.py\n",
    "# Code from Udacity\n",
    "\n",
    "schema = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "import cerberus\n",
    "import csv\n",
    "import schema\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        for node_attribute in NODE_FIELDS:\n",
    "            node_attribs[node_attribute] = element.attrib[node_attribute]\n",
    "        for child in element.iter():\n",
    "            if child.tag == 'tag':\n",
    "                if PROBLEMCHARS.match(child.attrib['k']) is not None:\n",
    "                    pass\n",
    "                else:\n",
    "                    if create_tag_dict(element, child):\n",
    "                        tags.append(create_tag_dict(element, child))\n",
    "                    else:\n",
    "                        continue\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        pos = 0\n",
    "        for way_attribute in WAY_FIELDS:\n",
    "            way_attribs[way_attribute] = element.attrib[way_attribute]\n",
    "        for child in element.iter():\n",
    "            if child.tag == 'tag':\n",
    "                if PROBLEMCHARS.match(child.attrib['k']) is not None:\n",
    "                    pass\n",
    "                else: \n",
    "                    if create_tag_dict(element, child):\n",
    "                        tags.append(create_tag_dict(element, child))\n",
    "                    else:\n",
    "                        continue\n",
    "            elif child.tag == 'nd':\n",
    "                nd = {}\n",
    "                nd['id'] = way_attribs['id']\n",
    "                nd['node_id'] = child.attrib['ref']\n",
    "                nd['position'] = pos\n",
    "                pos += 1\n",
    "                way_nodes.append(nd)\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "def create_tag_dict(element, child):\n",
    "    ''' str, str -> dict\n",
    "    Given the element of an XML doc and its child, return a dict of child element attribute values.\n",
    "    '''\n",
    "    d = {}\n",
    "    d['id'] = element.attrib['id']\n",
    "    d['key'] = child.attrib['k']\n",
    "    if ':' in child.attrib['k']:\n",
    "        index = child.attrib['k'].index(\":\") + 1\n",
    "        d[\"key\"] = child.attrib[\"k\"][index:]\n",
    "        d[\"type\"] = child.attrib[\"k\"][:index-1]\n",
    "        if is_street_name(child):\n",
    "            d['value'] = update_street_name(child.attrib['v'], street_mapping)\n",
    "        elif is_postcode(child):\n",
    "            d['value'] = update_postcode(child.attrib['v'])\n",
    "        else:\n",
    "            d['value'] = child.attrib['v']\n",
    "    else:\n",
    "        d['key'] = child.attrib['k']\n",
    "        d['type'] = 'regular'\n",
    "        d['value'] = child.attrib['v']\n",
    "    return d\n",
    "               \n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\" Note: Validation is ~ 10X slower. Run on SAMPLE_FILE. If no error, then set validate=False on OSM_FILE.\n",
    "    \"\"\"\n",
    "    process_map(OSM_FILE, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables\n",
    "\n",
    "Create nodes_tags table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1):\n",
      "[(25689368, u'highway', u'turning_circle', u'regular'),\n",
      " (25698637, u'name', u'King Soopers', u'regular'),\n",
      " (25698637, u'amenity', u'fuel', u'regular'),\n",
      " (25757229, u'name', u'King Soopers', u'regular'),\n",
      " (25757229, u'shop', u'supermarket', u'regular'),\n",
      " (25757782, u'highway', u'traffic_signals', u'regular'),\n",
      " (25758250, u'highway', u'crossing', u'regular'),\n",
      " (25765902, u'highway', u'traffic_signals', u'regular'),\n",
      " (25765915, u'highway', u'crossing', u'regular'),\n",
      " (25765941, u'amenity', u'restaurant', u'regular')]\n"
     ]
    }
   ],
   "source": [
    "sqlite_file = 'mydb.db'\n",
    "connection = sqlite3.connect(sqlite_file)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Drop the table if it already exists\n",
    "cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS nodes_tags\n",
    "    \"\"\")\n",
    "connection.commit()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE nodes_tags(id INTEGER, key TEXT, value TEXT, type TEXT)\n",
    "    \"\"\")\n",
    "connection.commit()\n",
    "\n",
    "# Read in data\n",
    "with open('nodes_tags.csv', 'rb') as f:\n",
    "    g = csv.DictReader(f)\n",
    "    to_db = [(i['id'], i['key'], i['value'].decode('utf-8'), i['type']) for i in g]\n",
    "\n",
    "# Insert data\n",
    "cursor.executemany(\"\"\"\n",
    "    INSERT INTO nodes_tags(id, key, value, type) VALUES (?, ?, ?, ?);\"\"\",\n",
    "    to_db)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "cursor.execute('SELECT * FROM nodes_tags LIMIT 10;')\n",
    "\n",
    "all_rows = cursor.fetchall()\n",
    "print('1):')\n",
    "pprint(all_rows)\n",
    "\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "Cannot operate on a closed database.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-29d161b13c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m cursor.execute(\"\"\"\n\u001b[1;32m      8\u001b[0m     \u001b[0mCREATE\u001b[0m \u001b[0mTABLE\u001b[0m \u001b[0mways_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m \u001b[0mINTEGER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_id\u001b[0m \u001b[0mINTEGER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m \u001b[0mINTEGER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \"\"\")\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: Cannot operate on a closed database."
     ]
    }
   ],
   "source": [
    "# Drop the table if it already exists\n",
    "cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS ways_nodes\n",
    "    \"\"\")\n",
    "connection.commit()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE ways_nodes(id INTEGER, node_id INTEGER, position INTEGER)\n",
    "    \"\"\")\n",
    "connection.commit()\n",
    "\n",
    "# Read in data\n",
    "with open('ways_nodes.csv', 'rb') as f:\n",
    "    g = csv.DictReader(f)\n",
    "    to_db = [(i['id'], i['node_id'], i['position']) for i in g]\n",
    "\n",
    "# Insert data\n",
    "cursor.executemany(\"\"\"\n",
    "    INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);\"\"\",\n",
    "    to_db)\n",
    "connection.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
